{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FQiOKlk03GgY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analisys with Recursive Neural Network\n",
        "※このNotebookは、[chainer/examples/sentiment](https://github.com/chainer/chainer/tree/master/examples/sentiment)を元に作成しています。scriptとして実行したい場合はそちらを参照してください。\n",
        "\n",
        "このNotebookでは、Reccurent Neural Networkを用いて文書の感情分析を行います。"
      ]
    },
    {
      "metadata": {
        "id": "UC-m7Hwh4Y7Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずは、以下のセルを実行して、ChainerとそのGPUバックエンドであるCuPyをインストールします。Colaboratoryの「ランタイムのタイプ」がGPUであれば、このコマンドを実行することでGPUをバックエンドとしてChainerを動かすことができます。"
      ]
    },
    {
      "metadata": {
        "id": "vctT_8EWSEOJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "d29592a3-92d6-41b3-d129-044b4c41baa5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526825898219,
          "user_tz": -540,
          "elapsed": 6513,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install -q cupy-cuda80 chainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcusparse8.0 is already the newest version (8.0.61-1).\n",
            "libnvrtc8.0 is already the newest version (8.0.61-1).\n",
            "libnvtoolsext1 is already the newest version (8.0.61-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cH8mST0B5IK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "必要なモジュールを``import``し、最後にChainerのバージョンやNumPy・CuPy、そしてCuda等の実行環境を確認してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "v00bch6E5Gf6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "1a7037b0-c455-4d96-90d1-8934a49f4cce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526825899025,
          "user_tz": -540,
          "elapsed": 717,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer.training import extensions\n",
        "from chainer import reporter\n",
        "\n",
        "\n",
        "chainer.print_runtime_info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chainer: 4.0.0\n",
            "NumPy: 1.14.3\n",
            "CuPy:\n",
            "  CuPy Version          : 4.0.0\n",
            "  CUDA Root             : None\n",
            "  CUDA Build Version    : 8000\n",
            "  CUDA Driver Version   : 9000\n",
            "  CUDA Runtime Version  : 8000\n",
            "  cuDNN Build Version   : 7102\n",
            "  cuDNN Version         : 7102\n",
            "  NCCL Build Version    : 2104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q735WN-T6C4J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. 学習データの用意\n",
        "このNotebookでは、[chainer/examples/sentiment/download.py](https://github.com/chainer/chainer/tree/master/examples/sentiment/download.py)で前処理された文書データを学習データに使用することを想定しています。以下のセルを実行して、必要な学習データをダウンロードし、解凍しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "nZVIeRChTmM5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# download.py\n",
        "import os.path\n",
        "from six.moves.urllib import request\n",
        "import zipfile\n",
        "\n",
        "\n",
        "request.urlretrieve(\n",
        "    'https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip',\n",
        "    'trainDevTestTrees_PTB.zip')\n",
        "zf = zipfile.ZipFile('trainDevTestTrees_PTB.zip')\n",
        "for name in zf.namelist():\n",
        "    (dirname, filename) = os.path.split(name)\n",
        "    if not filename == '':\n",
        "        zf.extract(name, '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "serSskBV69nB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以下のコマンドを実行して学習データが用意できたか確認してみましょう。\n",
        "\n",
        "```\n",
        "dev.txt  test.txt  train.txt\n",
        "```\n",
        "と表示されればダウンロードできています。"
      ]
    },
    {
      "metadata": {
        "id": "ry-1ylFZiMQ9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6dd5ac0f-dfdb-4208-ca3b-98892afe555a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526825904048,
          "user_tz": -540,
          "elapsed": 1765,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls trees"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZOMNLMahSFRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "``test.txt``の1行目を見て、各サンプルがどのように記述されているか見てみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "ob5vJeMNSSmQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "86165503-d6b2-4413-e6e2-75b715089bf9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526825906009,
          "user_tz": -540,
          "elapsed": 1919,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!head trees/dev.txt -n1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3 (2 It) (4 (4 (2 's) (4 (3 (2 a) (4 (3 lovely) (2 film))) (3 (2 with) (4 (3 (3 lovely) (2 performances)) (2 (2 by) (2 (2 (2 Buy) (2 and)) (2 Accorsi))))))) (2 .)))\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y5Xqp9n7Srjr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上記のように、各サンプルは木構造によって定義されています。\n",
        "\n",
        "木構造を再帰的に``(value, node)``として定義していると思いますが、この時``node``に対するクラスラベルが``value``になります。\n",
        "\n",
        "クラスラベルはそれぞれ、1(really negative)、2(negative)、3(neutral)、4(positive)、5(really positive)を表現しています。\n",
        "\n",
        "試しにあるサンプルを図で表現したものが下記になります。\n",
        "\n",
        "<img src=\"http://slideplayer.com/slide/6336754/22/images/4/Sentiment+Analysis+(Socher+et+al,+2013).jpg\" width=\"600\">"
      ]
    },
    {
      "metadata": {
        "id": "kjBUS6Cr8Sye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. パラメータの設定\n",
        "学習を行う際のパラメータをここで予め設定します。\n",
        "* エポック数 ``n_epoch``：学習時にtrainデータを何周させるか。\n",
        "* ユニット数 ``n_units``：Recursive Neural Networkの各ノードが何次元の隠れ状態ベクトルを持つか。\n",
        "* バッチサイズ ``batchsize``：パラメータの更新をする際にいくつのtrainデータを一塊として学習させるか。\n",
        "* ラベル数 ``n_label``：識別する問題のクラス数。今回は5ラベルあるので``5``。\n",
        "* ``epoch_per_eval``：何epochごとにvalidationを行うか\n",
        "* ``is_test``：動作確認のために小さいデータセットを使うか。``True``なら小さいデータセットを使う。\n",
        "* GPU ID ``gpu_id``：使用するGPUのID。Colaboratoryの場合``0``で良い。\n"
      ]
    },
    {
      "metadata": {
        "id": "1Ha6-ramShVF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "n_epoch = 100  # number of epochs\n",
        "n_units = 30  # number of units per layer\n",
        "batchsize = 25  # minibatch size\n",
        "n_label = 5  # number of labels\n",
        "epoch_per_eval = 5  # number of epochs per evaluation\n",
        "is_test = True\n",
        "gpu_id = 0\n",
        "\n",
        "if is_test:\n",
        "    max_size = 10\n",
        "else:\n",
        "    max_size = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q3PnMSM78akB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ３. イテレータの準備\n",
        "\n",
        "training、validation、testに使用するデータセットを読みこみ、Iteratorを作成しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "PqEzpAzMeMVo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# data.py\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "\n",
        "class SexpParser(object):\n",
        "\n",
        "    def __init__(self, line):\n",
        "        self.tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
        "        self.pos = 0\n",
        "\n",
        "    def parse(self):\n",
        "        assert self.pos < len(self.tokens)\n",
        "        token = self.tokens[self.pos]\n",
        "        assert token != ')'\n",
        "        self.pos += 1\n",
        "\n",
        "        if token == '(':\n",
        "            children = []\n",
        "            while True:\n",
        "                assert self.pos < len(self.tokens)\n",
        "                if self.tokens[self.pos] == ')':\n",
        "                    self.pos += 1\n",
        "                    break\n",
        "                else:\n",
        "                    children.append(self.parse())\n",
        "            return children\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "\n",
        "def read_corpus(path, max_size):\n",
        "    with codecs.open(path, encoding='utf-8') as f:\n",
        "        trees = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            tree = SexpParser(line).parse()\n",
        "            trees.append(tree)\n",
        "            if max_size and len(trees) >= max_size:\n",
        "                break\n",
        "\n",
        "    return trees\n",
        "\n",
        "  \n",
        "def convert_tree(vocab, exp):\n",
        "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
        "\n",
        "    if len(exp) == 2:\n",
        "        label, leaf = exp\n",
        "        if leaf not in vocab:\n",
        "            vocab[leaf] = len(vocab)\n",
        "        return {'label': int(label), 'node': vocab[leaf]}\n",
        "    elif len(exp) == 3:\n",
        "        label, left, right = exp\n",
        "        node = (convert_tree(vocab, left), convert_tree(vocab, right))\n",
        "        return {'label': int(label), 'node': node}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ermPnCx061Hq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "まずは、文字列で表現されている各サンプルをdictionary型で表現される木構造のデータ型に変換します。\n",
        "\n",
        "パーサ``SexpParser``によって実装された``read_corpus``により、文字列をtokenizeします。\n",
        "\n",
        "その後、tokenizeされた各サンプルを``convert_tree``により、dictionary型で表現される木構造にします。\n",
        "\n",
        "このようにすることで、ラベルはint、nodeは2要素のタプル、木構造をdictionaryで表現することができ、元の文字列よりも扱いやすいデータ構造になります。\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "42l-fDBfRijd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "    \n",
        "train_data = [convert_tree(vocab, tree) \n",
        "                        for tree in read_corpus('trees/train.txt', max_size)]\n",
        "train_iter = chainer.iterators.SerialIterator(train_data, batchsize)\n",
        "\n",
        "validation_data = [convert_tree(vocab, tree) \n",
        "                                 for tree in read_corpus('trees/dev.txt', max_size)]\n",
        "validation_iter = chainer.iterators.SerialIterator(validation_data, batchsize, \n",
        "                                                                                   repeat=False, shuffle=False)\n",
        "\n",
        "test_data = [convert_tree(vocab, tree) \n",
        "                        for tree in read_corpus('trees/test.txt', max_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xE3MSUrj92Tn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "試しに、1つ目の``test_data``を表示してみましょう。以下のような木構造で表現されており、``lable``はその``node``以下のscoreを表現しており、末端``node``の数値は辞書``vocab``内の単語のidです。"
      ]
    },
    {
      "metadata": {
        "id": "aE4YORp2eQP9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "76143266-42bf-4c2d-e319-6f993785a652",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526825909372,
          "user_tz": -540,
          "elapsed": 725,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': 2, 'node': ({'label': 3, 'node': ({'label': 3, 'node': 252}, {'label': 2, 'node': 71})}, {'label': 1, 'node': ({'label': 1, 'node': 253}, {'label': 2, 'node': 254})})}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GVUZPtjo8ycv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. モデルの準備\n",
        "\n",
        "使用するネットワークを定義しましょう。"
      ]
    },
    {
      "metadata": {
        "id": "eU55nEkoE_Kc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "``traverse``により木構造データの各ノードを辿り、木全体での損失``loss``を計算します。``traverse``は再帰呼出しになっており、順々に子ノードをたどるような実装になっています。(木構造データを扱う時によくある実装ですね！)\n",
        "\n",
        "まず、隠れ状態ベクトル``v``を計算します。リーフノードの場合、単語id ``word``から``model.leaf(word)``によって``embed``に保存されている隠れ状態ベクトルを取得します。中間ノードの場合、各子ノードから返された子ノードの隠れ状態ベクトル``left``、``right``から``v = model.node(left, right)``により計算します。\n",
        "\n",
        "``loss += F.softmax_cross_entropy(y, t)``で現在のノードのlossを子ノードのlossに足し合わせ、最後に``return loss, v``で親ノードにlossを返しています。\n",
        "\n",
        "`` loss += F.softmax_cross_entropy(y, t)``以降に色々書いてありますが、これは正答率などをロギングするためにあるものなので、modelの定義自体には不必要です。"
      ]
    },
    {
      "metadata": {
        "id": "aGICf_k0hzW8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class RecursiveNet(chainer.Chain):\n",
        "  \n",
        "    def traverse(self, node, evaluate=None, root=True):\n",
        "        if isinstance(node['node'], int):\n",
        "            # leaf node\n",
        "            word = self.xp.array([node['node']], np.int32)\n",
        "            loss = 0\n",
        "            v = model.leaf(word)\n",
        "        else:\n",
        "            # internal node\n",
        "            left_node, right_node = node['node']\n",
        "            left_loss, left = self.traverse(left_node, evaluate=evaluate, root=False)\n",
        "            right_loss, right = self.traverse(right_node, evaluate=evaluate, root=False)\n",
        "            v = model.node(left, right)\n",
        "            loss = left_loss + right_loss\n",
        "\n",
        "        y = model.label(v)\n",
        "\n",
        "        label = self.xp.array([node['label']], np.int32)\n",
        "        t = chainer.Variable(label)\n",
        "        loss += F.softmax_cross_entropy(y, t)\n",
        "\n",
        "        predict = cuda.to_cpu(y.data.argmax(1))\n",
        "        if predict[0] == node['label']:\n",
        "            evaluate['correct_node'] += 1\n",
        "        evaluate['total_node'] += 1\n",
        "  \n",
        "        if root:\n",
        "            if predict[0] == node['label']:\n",
        "                evaluate['correct_root'] += 1\n",
        "            evaluate['total_root'] += 1\n",
        "\n",
        "        return loss, v\n",
        "\n",
        "    def __init__(self, n_vocab, n_units):\n",
        "        super(RecursiveNet, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(n_vocab, n_units)\n",
        "            self.l = L.Linear(n_units * 2, n_units)\n",
        "            self.w = L.Linear(n_units, n_label)\n",
        "\n",
        "    def leaf(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "    def node(self, left, right):\n",
        "        return F.tanh(self.l(F.concat((left, right))))\n",
        "\n",
        "    def label(self, v):\n",
        "        return self.w(v)\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        accum_loss = 0.0\n",
        "        result = collections.defaultdict(lambda: 0)\n",
        "        for tree in x:\n",
        "            loss, _ = self.traverse(tree, evaluate=result)\n",
        "            accum_loss += loss\n",
        "        \n",
        "        reporter.report({'loss': accum_loss}, self)\n",
        "        reporter.report({'total': result['total_node']}, self)\n",
        "        reporter.report({'correct': result['correct_node']}, self)\n",
        "        return accum_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYsIEJUI_Km4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ここで、``__call__``の実装に1つ注意があります。\n",
        "\n",
        "``__call__``に渡される``x``はミニバッチ化された入力データであり、``[s_1, s_2, ..., s_N]``のように各サンプル``s_n``が入っています。\n",
        "\n",
        "画像認識で使うConvolutional Networkなどのネットワークの場合、ミニバッチ``x``に対して一括で並列計算を行うことができます。しかし、今回のような木構造のネットワークの場合、以下の点で並列計算することが難しく、1つ1つのサンプルに対して計算を行い、最後に結果を集約するような実装になっています。\n",
        "\n",
        "* データ長がサンプルによって異なる\n",
        "* 各サンプルに対する計算順序が異なる\n",
        "\n",
        "※実は、スタックを利用してRecursive Neural Networkでもミニバッチの並列計算を行うことができます。(発展)として後ろの方で掲載しているので参照ください。\n"
      ]
    },
    {
      "metadata": {
        "id": "TnBhdpO8igK9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = RecursiveNet(len(vocab), n_units)\n",
        "\n",
        "if gpu_id >= 0:\n",
        "    model.to_gpu()\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = chainer.optimizers.AdaGrad(lr=0.1)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(0.0001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OTq_sX298-ZR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Updater・Trainerの準備と学習の実行\n",
        "\n",
        "いつものように、UpdaterとTrainerを定義して、modelを学習させます。\n",
        "今回、``L.Classifier``を使用せず、自分で精度``accuracy``を計算しています。``extensions.MicroAverage``を使用すると簡単に実装することができます。詳しくは、[chainer.training.extensions.MicroAverage](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.MicroAverage.html)を参照ください。"
      ]
    },
    {
      "metadata": {
        "id": "nXAIZSy9cQdu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "a62ac617-4c28-4500-ce0f-59b55183d23d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526826006469,
          "user_tz": -540,
          "elapsed": 95394,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def _convert(batch, device):\n",
        "  return batch\n",
        "\n",
        "updater = chainer.training.StandardUpdater(\n",
        "    train_iter, optimizer, device=gpu_id, converter=_convert)\n",
        "\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'))\n",
        "trainer.extend(\n",
        "        extensions.Evaluator(validation_iter, model, device=gpu_id, converter=_convert),\n",
        "        trigger=(epoch_per_eval, 'epoch'))\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'main/correct', 'main/total', 'main/accuracy'))\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'validation/main/correct', 'validation/main/total',\n",
        "        'validation/main/accuracy'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'validation/main/loss',\n",
        "          'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "trainer.run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           1620.74                           0.245495                                 5.10428       \n",
            "\u001b[J2           545.169     551.23                0.587838       0.442623                  7.81332       \n",
            "\u001b[J3           395.948                           0.72973                                  9.70386       \n",
            "\u001b[J4           374.31      546.901               0.731982       0.459016                  12.3539       \n",
            "\u001b[J5           345.539                           0.768018                                 14.2971       \n",
            "\u001b[J6           227.336     551.377               0.896396       0.494536                  16.9247       \n",
            "\u001b[J7           167.934                           0.936937                                 18.8253       \n",
            "\u001b[J8           126.277     570.017               0.954955       0.497268                  21.5186       \n",
            "\u001b[J9           98.0478                           0.972973                                 23.4103       \n",
            "\u001b[J10          77.475      594.685               0.984234       0.502732                  26.1162       \n",
            "\u001b[J11          62.3243                           0.986486                                 27.9949       \n",
            "\u001b[J12          50.843      617.205               0.990991       0.513661                  30.6482       \n",
            "\u001b[J13          42.1133                           0.990991                                 32.6093       \n",
            "\u001b[J14          35.4103     635.552               0.995495       0.513661                  35.2373       \n",
            "\u001b[J15          30.0894                           0.997748                                 37.1427       \n",
            "\u001b[J16          25.6345     650.352               0.997748       0.516393                  39.8406       \n",
            "\u001b[J17          22.1484                           0.997748                                 41.7452       \n",
            "\u001b[J18          19.4407     662.344               0.997748       0.516393                  44.3749       \n",
            "\u001b[J19          17.1996                           1                                        46.3293       \n",
            "\u001b[J20          15.3029     672.085               1              0.521858                  48.974        \n",
            "\u001b[J21          13.701                            1                                        50.8809       \n",
            "\u001b[J22          12.3821     680.558               1              0.521858                  53.5715       \n",
            "\u001b[J23          11.2896                           1                                        55.4855       \n",
            "\u001b[J24          10.3658     687.382               1              0.52459                   58.1776       \n",
            "\u001b[J25          9.57276                           1                                        60.0696       \n",
            "\u001b[J26          8.88406     692.939               1              0.527322                  62.705        \n",
            "\u001b[J27          8.28042                           1                                        64.6225       \n",
            "\u001b[J28          7.74716     697.521               1              0.532787                  67.2185       \n",
            "\u001b[J29          7.27279                           1                                        69.1315       \n",
            "\u001b[J30          6.84818     701.334               1              0.530055                  71.8325       \n",
            "\u001b[J31          6.46594                           1                                        73.7415       \n",
            "\u001b[J32          6.12004     704.532               1              0.530055                  76.3853       \n",
            "\u001b[J33          5.80552                           1                                        78.3144       \n",
            "\u001b[J34          5.51829     707.233               1              0.527322                  80.8981       \n",
            "\u001b[J35          5.25492                           1                                        82.809        \n",
            "\u001b[J36          5.01261     709.529               1              0.527322                  85.5038       \n",
            "\u001b[J37          4.78903                           1                                        87.3981       \n",
            "\u001b[J38          4.5823      711.501               1              0.527322                  90.0571       \n",
            "\u001b[J39          4.39086                           1                                        91.9491       \n",
            "\u001b[J40          4.21337     713.221               1              0.527322                  94.6118       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N7wiomoIvjc1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. テストデータでの性能の確認"
      ]
    },
    {
      "metadata": {
        "id": "J4g1JkNWv86t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "100fb2a3-3cc1-4853-d1fe-c2074a368aac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526826008076,
          "user_tz": -540,
          "elapsed": 1577,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_trees):\n",
        "    result = collections.defaultdict(lambda: 0)\n",
        "    with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
        "        for tree in test_trees:\n",
        "            model.traverse(tree, evaluate=result)\n",
        "    acc_node = 100.0 * result['correct_node'] / result['total_node']\n",
        "    acc_root = 100.0 * result['correct_root'] / result['total_root']\n",
        "    print(' Node accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_node, result['correct_node'], result['total_node']))\n",
        "    print(' Root accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_root, result['correct_root'], result['total_root']))\n",
        "            \n",
        "print('Test evaluation')\n",
        "evaluate(model, test_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test evaluation\n",
            " Node accuracy: 50.00 %% (156/312)\n",
            " Root accuracy: 40.00 %% (4/10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rVhX6oQe9eIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# (発展) Recursive Neural Networkにおけるミニバッチ化[1]\n",
        "\n",
        "Recursive Neural Networkは、以下の点からミニバッチ化されたデータを並列計算することが難しいです。\n",
        "\n",
        "* データ長がサンプルによって異なる\n",
        "* 各サンプルに対する計算順序が異なる\n",
        "\n",
        "しかし、スタックを利用してRecursive Neural Networkでもミニバッチの並列計算を行うことができます。"
      ]
    },
    {
      "metadata": {
        "id": "0n0Nm1wqKr_l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset, Iteratorの用意\n",
        "まず、Recursive Neural Networkの再帰的な伝播計算をスタックを用いる直列的な計算に変換するために、データセットを直列的なデータセットに変換します。\n",
        "\n",
        "木構造データセットの各ノードに対して、以下のように木に対して帰りがけ順に番号を振ります。\n",
        "\n",
        "<img src=\"https://cdn-ak.f.st-hatena.com/images/fotolife/k/kumechann/20180519/20180519103841.png\" width=\"300\">\n",
        "\n",
        "帰りがけ順とは、木構造のノードに番号をつける手順の一つで、全ての子ノードに親ノードよりも小さい番号をつける手順です。この手順で割り当てられたノードを、番号の小さい順にだどりながら処理を行うと、必ず親ノードの前に子ノードをたどることができます。\n"
      ]
    },
    {
      "metadata": {
        "id": "JhCaQqMrwrjj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def linearize_tree(vocab, root, xp=np):\n",
        "    # Left node indexes for all parent nodes\n",
        "    lefts = []\n",
        "    # Right node indexes for all parent nodes\n",
        "    rights = []\n",
        "    # Parent node indexes\n",
        "    dests = []\n",
        "    # All labels to predict for all parent nodes\n",
        "    labels = []\n",
        "\n",
        "    # All words of leaf nodes\n",
        "    words = []\n",
        "    # Leaf labels\n",
        "    leaf_labels = []\n",
        "\n",
        "    # Current leaf node index\n",
        "    leaf_index = [0]\n",
        "\n",
        "    def traverse_leaf(exp):\n",
        "        if len(exp) == 2:\n",
        "            label, leaf = exp\n",
        "            if leaf not in vocab:\n",
        "                vocab[leaf] = len(vocab)\n",
        "            words.append(vocab[leaf])\n",
        "            leaf_labels.append(int(label))\n",
        "            leaf_index[0] += 1\n",
        "        elif len(exp) == 3:\n",
        "            _, left, right = exp\n",
        "            traverse_leaf(left)\n",
        "            traverse_leaf(right)\n",
        "\n",
        "    traverse_leaf(root)\n",
        "\n",
        "    # Current internal node index\n",
        "    node_index = leaf_index\n",
        "    leaf_index = [0]\n",
        "\n",
        "    def traverse_node(exp):\n",
        "        if len(exp) == 2:\n",
        "            leaf_index[0] += 1\n",
        "            return leaf_index[0] - 1\n",
        "        elif len(exp) == 3:\n",
        "            label, left, right = exp\n",
        "            l = traverse_node(left)\n",
        "            r = traverse_node(right)\n",
        "\n",
        "            lefts.append(l)\n",
        "            rights.append(r)\n",
        "            dests.append(node_index[0])\n",
        "            labels.append(int(label))\n",
        "\n",
        "            node_index[0] += 1\n",
        "            return node_index[0] - 1\n",
        "\n",
        "    traverse_node(root)\n",
        "    assert len(lefts) == len(words) - 1\n",
        "\n",
        "    return {\n",
        "        'lefts': xp.array(lefts, 'i'),\n",
        "        'rights': xp.array(rights, 'i'),\n",
        "        'dests': xp.array(dests, 'i'),\n",
        "        'words': xp.array(words, 'i'),\n",
        "        'labels': xp.array(labels, 'i'),\n",
        "        'leaf_labels': xp.array(leaf_labels, 'i'),\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2nu45Tiw0CY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "xp = cuda.cupy if gpu_id >= 0 else np\n",
        "\n",
        "vocab = {}\n",
        "\n",
        "train_data = [linearize_tree(vocab, t, xp)\n",
        "                        for t in read_corpus('trees/train.txt', max_size)]\n",
        "train_iter = chainer.iterators.SerialIterator(train_data, batchsize)\n",
        "\n",
        "validation_data = [linearize_tree(vocab, t, xp)\n",
        "                       for t in read_corpus('trees/dev.txt', max_size)]\n",
        "validation_iter = chainer.iterators.SerialIterator(\n",
        "    validation_data, batchsize, repeat=False, shuffle=False)\n",
        "\n",
        "test_data = [linearize_tree(vocab, t, xp)\n",
        "                       for t in read_corpus('trees/test.txt', max_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8D3CHRKDngQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "試しに、1つ目のtest_dataを表示してみましょう。\n",
        "\n",
        "``lefts``には親ノード``dests``に対する左ノードのindex、``rights``には親ノード``dests``に対する右ノードのindex、``dests``には親ノードのindex、``words``には葉ノードの単語id、``labels``には親ノードのラベル、``leaf_labels``には葉ノードのラベルが入った辞書が生成されています。"
      ]
    },
    {
      "metadata": {
        "id": "UGmbQTWvDuwB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7dd732aa-a61c-4990-835d-7818e81aaaeb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526826011548,
          "user_tz": -540,
          "elapsed": 775,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lefts': array([0, 2, 4], dtype=int32), 'rights': array([1, 3, 5], dtype=int32), 'dests': array([4, 5, 6], dtype=int32), 'words': array([252,  71, 253, 254], dtype=int32), 'labels': array([3, 1, 2], dtype=int32), 'leaf_labels': array([3, 2, 1, 2], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TV7FdFj8Kw6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ミニバッチ化可能なモデルの定義"
      ]
    },
    {
      "metadata": {
        "id": "KCBnHB50WwmI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recursive Neural Networkでは、葉ノードに対して埋め込みベクトルを計算する操作Aと、2つの子ノードの隠れ状態ベクトルから親ノードの隠れ状態ベクトルを計算する操作Bの2つがあります。\n",
        "\n",
        "各サンプルに対して、帰りがけ順にノードに``index``をふりました。帰りがけ順にノードをたどると、葉ノードでは操作Aを、それ以外のノードでは操作Bを行えばよいことがわかります。\n",
        "\n",
        "この操作はスタックを利用して、木構造を走査しているとみなすこともできます。スタックとは後入れ先出しのデータ構造で、データを追加するプッシュ操作と、最後にプッシュされたデータを取得するポップ操作の2つを行えます。\n",
        "\n",
        "操作Aのときは計算結果をスタックにプッシュする操作を、操作Bのときは2つのデータをポップし、その計算結果をプッシュする操作を行います。\n",
        "\n",
        "上記操作を並列化しますが、各サンプルごとに木構造は違うので、うまく分岐して操作Aと操作Bを行う必要があります。この時、スタックを使うことによって、異なる木構造のデータに対しても同様な処理の単純な繰り返しを行うことでRecursive Neural Networkの計算を行うことができます。そのため、並列化可能です。"
      ]
    },
    {
      "metadata": {
        "id": "o7NxCajVRDIY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer import cuda\n",
        "from chainer.utils import type_check\n",
        "\n",
        "\n",
        "class ThinStackSet(chainer.Function):\n",
        "    \"\"\"Set values to a thin stack.\"\"\"\n",
        "\n",
        "    def check_type_forward(self, in_types):\n",
        "        type_check.expect(in_types.size() == 3)\n",
        "        s_type, i_type, v_type = in_types\n",
        "        type_check.expect(\n",
        "            s_type.dtype.kind == 'f',\n",
        "            i_type.dtype.kind == 'i',\n",
        "            s_type.dtype == v_type.dtype,\n",
        "            s_type.ndim == 3,\n",
        "            i_type.ndim == 1,\n",
        "            v_type.ndim == 2,\n",
        "            s_type.shape[0] >= i_type.shape[0],\n",
        "            i_type.shape[0] == v_type.shape[0],\n",
        "            s_type.shape[2] == v_type.shape[1],\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        xp = cuda.get_array_module(*inputs)\n",
        "        stack, indices, values = inputs\n",
        "        stack[xp.arange(len(indices)), indices] = values\n",
        "        return stack,\n",
        "\n",
        "    def backward(self, inputs, grads):\n",
        "        xp = cuda.get_array_module(*inputs)\n",
        "        _, indices, _ = inputs\n",
        "        g = grads[0]\n",
        "        gv = g[xp.arange(len(indices)), indices]\n",
        "        g[xp.arange(len(indices)), indices] = 0\n",
        "        return g, None, gv\n",
        "\n",
        "\n",
        "def thin_stack_set(s, i, x):\n",
        "    return ThinStackSet()(s, i, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8t4bR-W704up",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "さらに、ここでは単純なスタックではなく、シンスタック[2]を使います。\n",
        "\n",
        "文長を``I``、隠れベクトルの次元数を``D``とすると、シンスタックは``(2I-1) x D``の行列を使いまわすことでメモリ領域を効率的に利用することができます。\n",
        "\n",
        "通常のスタックでは``O(I^2 D)``の空間計算量を必要とするところ、シンスタックは``O(ID)``で済みます。\n",
        "\n",
        "プッシュ操作``thin_stack_set``とポップ操作``thin_stack_get``によって実現しています。\n",
        "\n",
        "まずは、``chainer.Function``を継承した``ThinStackSet``と``ThinStackGet``を定義します。\n",
        "\n",
        "``ThinStackSet``は文字通り、シンスタックに値をセットするための関数でです。\n",
        "\n",
        "``forward``、``backward``の``inputs``は、``stack, indices, values = inputs``のように分解できます。\n",
        "\n",
        "``stack``は名前の通り、シンスタック自身で関数の引数にすることで、関数間で受け渡すようにしています。\n",
        "\n",
        "というのも、``chainer.Function``は内部に状態を持たない構造になっており、関数の引数で受け渡すことで、外部で``stack``を管理するようになっています。"
      ]
    },
    {
      "metadata": {
        "id": "s5P9sQzGCg6G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ThinStackGet(chainer.Function):\n",
        "\n",
        "    def check_type_forward(self, in_types):\n",
        "        type_check.expect(in_types.size() == 2)\n",
        "        s_type, i_type = in_types\n",
        "        type_check.expect(\n",
        "            s_type.dtype.kind == 'f',\n",
        "            i_type.dtype.kind == 'i',\n",
        "            s_type.ndim == 3,\n",
        "            i_type.ndim == 1,\n",
        "            s_type.shape[0] >= i_type.shape[0],\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        xp = cuda.get_array_module(*inputs)\n",
        "        stack, indices = inputs\n",
        "        return stack[xp.arange(len(indices)), indices], stack\n",
        "\n",
        "    def backward(self, inputs, grads):\n",
        "        xp = cuda.get_array_module(*inputs)\n",
        "        stack, indices = inputs\n",
        "        g, gs = grads\n",
        "        if gs is None:\n",
        "            gs = xp.zeros_like(stack)\n",
        "        if g is not None:\n",
        "            gs[xp.arange(len(indices)), indices] += g\n",
        "        return gs, None\n",
        "\n",
        "\n",
        "def thin_stack_get(s, i):\n",
        "    return ThinStackGet()(s, i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5TLGCBDazDod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "``ThinStackGet``は文字通り、シンスタックから値を取得するための関数です。\n",
        "\n",
        "``forward``、``backward``の``inputs``は、``stack, indices = inputs``のように分解できます。"
      ]
    },
    {
      "metadata": {
        "id": "69Dpc3TrKe1Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ThinStackRecursiveNet(chainer.Chain):\n",
        "\n",
        "    def __init__(self, n_vocab, n_units, n_label):\n",
        "        super(ThinStackRecursiveNet, self).__init__(\n",
        "            embed=L.EmbedID(n_vocab, n_units),\n",
        "            l=L.Linear(n_units * 2, n_units),\n",
        "            w=L.Linear(n_units, n_label))\n",
        "        self.n_units = n_units\n",
        "\n",
        "    def leaf(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "    def node(self, left, right):\n",
        "        return F.tanh(self.l(F.concat((left, right))))\n",
        "\n",
        "    def label(self, v):\n",
        "        return self.w(v)\n",
        "\n",
        "    def __call__(self, *inputs):\n",
        "        batch = len(inputs) // 6\n",
        "        lefts = inputs[0: batch]\n",
        "        rights = inputs[batch: batch * 2]\n",
        "        dests = inputs[batch * 2: batch * 3]\n",
        "        labels = inputs[batch * 3: batch * 4]\n",
        "        sequences = inputs[batch * 4: batch * 5]\n",
        "        leaf_labels = inputs[batch * 5: batch * 6]\n",
        "\n",
        "        inds = np.argsort([-len(l) for l in lefts])\n",
        "        # Sort all arrays in descending order and transpose them\n",
        "        lefts = F.transpose_sequence([lefts[i] for i in inds])\n",
        "        rights = F.transpose_sequence([rights[i] for i in inds])\n",
        "        dests = F.transpose_sequence([dests[i] for i in inds])\n",
        "        labels = F.transpose_sequence([labels[i] for i in inds])\n",
        "        sequences = F.transpose_sequence([sequences[i] for i in inds])\n",
        "        leaf_labels = F.transpose_sequence([leaf_labels[i] for i in inds])\n",
        "\n",
        "        batch = len(inds)\n",
        "        maxlen = len(sequences)\n",
        "\n",
        "        loss = 0\n",
        "        count = 0\n",
        "        correct = 0\n",
        "\n",
        "        # thin stack\n",
        "        stack = self.xp.zeros((batch, maxlen * 2, self.n_units), 'f')\n",
        "\n",
        "        # 葉ノードの隠れ状態ベクトルとlossを計算\n",
        "        for i, (word, label) in enumerate(zip(sequences, leaf_labels)):\n",
        "            batch = word.shape[0]\n",
        "            es = self.leaf(word)\n",
        "            ds = self.xp.full((batch,), i, 'i')\n",
        "            y = self.label(es)\n",
        "            loss += F.softmax_cross_entropy(y, label, normalize=False) * batch\n",
        "            count += batch\n",
        "            predict = self.xp.argmax(y.data, axis=1)\n",
        "            correct += (predict == label.data).sum()\n",
        "\n",
        "            stack = thin_stack_set(stack, ds, es)\n",
        "\n",
        "        # 中間ノードの隠れ状態ベクトルとlossを計算\n",
        "        for left, right, dest, label in zip(lefts, rights, dests, labels):\n",
        "            l, stack = thin_stack_get(stack, left)\n",
        "            r, stack = thin_stack_get(stack, right)\n",
        "            o = self.node(l, r)\n",
        "            y = self.label(o)\n",
        "            batch = l.shape[0]\n",
        "            loss += F.softmax_cross_entropy(y, label, normalize=False) * batch\n",
        "            count += batch\n",
        "            predict = self.xp.argmax(y.data, axis=1)\n",
        "            correct += (predict == label.data).sum()\n",
        "\n",
        "            stack = thin_stack_set(stack, dest, o)\n",
        "\n",
        "        loss /= count\n",
        "        reporter.report({'loss': loss}, self)\n",
        "        reporter.report({'total': count}, self)\n",
        "        reporter.report({'correct': correct}, self)\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wzaoOvy-CE83",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d52ad030-d23a-4b3a-d2b8-f2ba74aeabb7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526826017145,
          "user_tz": -540,
          "elapsed": 760,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = ThinStackRecursiveNet(len(vocab), n_units, n_label)\n",
        "\n",
        "if gpu_id >= 0:\n",
        "    model.to_gpu()\n",
        "    \n",
        "optimizer = chainer.optimizers.AdaGrad(0.1)\n",
        "optimizer.setup(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.optimizers.ada_grad.AdaGrad at 0x7f8a3c453710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "vP8_30gMLAjT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Updater・Trainerの準備と学習の実行\n",
        "では、さっそく新しく定義した``ThinStackRecursiveNet``をモデルにして学習させてみましょう。ミニバッチを並列計算することができるようになったので、学習が高速になっていることがわかると思います。"
      ]
    },
    {
      "metadata": {
        "id": "Dmhq_uyAxNd4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "28e94c4b-60d3-4e39-c841-2fb858cd6940",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526826052858,
          "user_tz": -540,
          "elapsed": 35667,
          "user": {
            "displayName": "Keisuke Umezawa",
            "photoUrl": "//lh3.googleusercontent.com/-KRaJUYLr9rk/AAAAAAAAAAI/AAAAAAAAABE/PM10WWYaRqk/s50-c-k-no/photo.jpg",
            "userId": "105009450683196526456"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def convert(batch, device):\n",
        "    if device is None:\n",
        "        def to_device(x):\n",
        "            return x\n",
        "    elif device < 0:\n",
        "        to_device = cuda.to_cpu\n",
        "    else:\n",
        "        def to_device(x):\n",
        "            return cuda.to_gpu(x, device, cuda.Stream.null)\n",
        "\n",
        "    return tuple(\n",
        "        [to_device(d['lefts']) for d in batch] +\n",
        "        [to_device(d['rights']) for d in batch] +\n",
        "        [to_device(d['dests']) for d in batch] +\n",
        "        [to_device(d['labels']) for d in batch] +\n",
        "        [to_device(d['words']) for d in batch] +\n",
        "        [to_device(d['leaf_labels']) for d in batch]\n",
        "    )\n",
        "  \n",
        "\n",
        "updater = chainer.training.StandardUpdater(\n",
        "    train_iter, optimizer, device=None, converter=convert)\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'))\n",
        "trainer.extend(\n",
        "    extensions.Evaluator(validation_iter, model, converter=convert, device=None),\n",
        "    trigger=(epoch_per_eval, 'epoch'))\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "    'main/correct', 'main/total', 'main/accuracy'))\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "    'validation/main/correct', 'validation/main/total',\n",
        "    'validation/main/accuracy'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "   ['epoch', 'main/loss', 'validation/main/loss',\n",
        "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "trainer.run()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           1.75582                           0.268018                                 0.772637      \n",
            "\u001b[J2           1.0503      1.52234               0.63964        0.448087                  1.74078       \n",
            "\u001b[J3           0.752925                          0.743243                                 2.52495       \n",
            "\u001b[J4           1.21727     1.46956               0.745495       0.456284                  3.49669       \n",
            "\u001b[J5           0.681582                          0.817568                                 4.24974       \n",
            "\u001b[J6           0.477964    1.5514                0.880631       0.480874                  5.22265       \n",
            "\u001b[J7           0.38437                           0.916667                                 5.98324       \n",
            "\u001b[J8           0.30405     1.68066               0.923423       0.469945                  6.94833       \n",
            "\u001b[J9           0.222884                          0.959459                                 7.69772       \n",
            "\u001b[J10          0.175159    1.79104               0.977477       0.478142                  8.67923       \n",
            "\u001b[J11          0.142888                          0.97973                                  9.43108       \n",
            "\u001b[J12          0.118272    1.87948               0.986486       0.47541                   10.4046       \n",
            "\u001b[J13          0.0991659                         0.997748                                 11.1994       \n",
            "\u001b[J14          0.0841932   1.95415               0.997748       0.478142                  12.1657       \n",
            "\u001b[J15          0.0723124                         0.997748                                 12.9141       \n",
            "\u001b[J16          0.0627568   2.01682               0.997748       0.480874                  13.8787       \n",
            "\u001b[J17          0.0549726                         1                                        14.6336       \n",
            "\u001b[J18          0.04857     2.07107               1              0.478142                  15.6061       \n",
            "\u001b[J19          0.0432675                         1                                        16.3584       \n",
            "\u001b[J20          0.0388425   2.1181                1              0.480874                  17.3297       \n",
            "\u001b[J21          0.035117                          1                                        18.0761       \n",
            "\u001b[J22          0.0319522   2.15905               1              0.478142                  19.0487       \n",
            "\u001b[J23          0.0292416                         1                                        19.8416       \n",
            "\u001b[J24          0.0269031   2.1951                1              0.480874                  20.8083       \n",
            "\u001b[J25          0.0248729                         1                                        21.5566       \n",
            "\u001b[J26          0.0231      2.22721               1              0.483607                  22.5304       \n",
            "\u001b[J27          0.0215427                         1                                        23.2878       \n",
            "\u001b[J28          0.0201669   2.25614               1              0.486339                  24.2565       \n",
            "\u001b[J29          0.018944                          1                                        25.0171       \n",
            "\u001b[J30          0.017851    2.28247               1              0.480874                  26.0063       \n",
            "\u001b[J31          0.0168687                         1                                        26.7633       \n",
            "\u001b[J32          0.0159814   2.30664               1              0.483607                  27.7331       \n",
            "\u001b[J33          0.0151763                         1                                        28.5342       \n",
            "\u001b[J34          0.0144427   2.32898               1              0.483607                  29.5039       \n",
            "\u001b[J35          0.0137716                         1                                        30.257        \n",
            "\u001b[J36          0.0131555   2.34976               1              0.483607                  31.2306       \n",
            "\u001b[J37          0.0125881                         1                                        31.9842       \n",
            "\u001b[J38          0.0120638   2.3692                1              0.483607                  32.9617       \n",
            "\u001b[J39          0.0115783                         1                                        33.7175       \n",
            "\u001b[J40          0.0111272   2.38747               1              0.483607                  34.6946       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kIYQVBOAJ4eg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "だいぶ速くなりましたね！"
      ]
    },
    {
      "metadata": {
        "id": "_UBmkq3xYmSX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "[1] 深層学習による自然言語処理 (機械学習プロフェッショナルシリーズ)\n",
        "\n",
        "[2] [A Fast Unified Model for Parsing and Sentence Understanding](http://nlp.stanford.edu/pubs/bowman2016spinn.pdf)"
      ]
    }
  ]
}