{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-Write-the-training-loop_ja.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6wYcO_JXa7kj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 学習ループを書いてみよう\n",
        "\n",
        "ここでは、\n",
        "\n",
        "1. データセットからデータを取り出す\n",
        "2. モデルに入力する\n",
        "3. Optimizerを使ってモデルのパラメータを更新して学習を行うループを回す\n",
        "\n",
        "ことをやってみます。このノートから得られるものは、`Trainer`を使わない学習ループの書き方です。"
      ]
    },
    {
      "metadata": {
        "id": "1ZN45x4ebGge",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 9
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "650465ac-e6a5-42f1-c85c-4810e518d021",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518687218770,
          "user_tz": -540,
          "elapsed": 8182,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install Chainer and CuPy!\n",
        "\n",
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcusparse8.0 is already the newest version (8.0.61-1).\n",
            "libnvrtc8.0 is already the newest version (8.0.61-1).\n",
            "libnvtoolsext1 is already the newest version (8.0.61-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "Requirement already satisfied: cupy-cuda80==4.0.0b3 from https://github.com/kmaehashi/chainer-colab/releases/download/2018-02-06/cupy_cuda80-4.0.0b3-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.0.0b3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.0.0b3)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.0.0b3)\n",
            "Requirement already satisfied: chainer==4.0.0b3 in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer==4.0.0b3)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.0.0->chainer==4.0.0b3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cx-pv0Oda7kk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. データセットの準備\n",
        "\n",
        "ここでは、Chainerが用意しているMNISTデータセットを使うための便利なメソッドを利用します。これを使うと、データのダウンロードから、一つ一つのデータを取り出せるようにするところまでが隠蔽されます。"
      ]
    },
    {
      "metadata": {
        "id": "sTEqFAsua7kl",
        "colab_type": "code",
        "slideshow": {
          "slide_type": "-"
        },
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            },
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "51b59c0c-c138-4cb4-95c3-b5438d4d30ef",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518687220478,
          "user_tz": -540,
          "elapsed": 1687,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer.datasets import mnist\n",
        "\n",
        "# データセットがダウンロード済みでなければ、ダウンロードも行う\n",
        "train, test = mnist.get_mnist(withlabel=True, ndim=1)\n",
        "\n",
        "# matplotlibを使ったグラフ描画結果がnotebook内に表示されるようにします。\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# データの例示\n",
        "x, t = train[0]\n",
        "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "print('label:', t)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cupy/core/fusion.py:659: FutureWarning: cupy.core.fusion is experimental. The interface can change in the future.\n",
            "  util.experimental('cupy.core.fusion')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9acb85f278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R3_POVA1a7kp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Iteratorの作成\n",
        "\n",
        "データセットから決まった数のデータを取り出し、それらを束ねてミニバッチを作成して返してくれる`Iterator`を作成しましょう。これをこの後の学習ループの中で使用していきます。イテレータは、`next()`メソッドで新しいミニバッチを返してくれます。内部ではデータセットを何周なめたか（`epoch`）、現在のイテレーションが新しいepochの最初のイテレーションか、などを管理するプロパティ（`is_new_epoch`）などを持っています。"
      ]
    },
    {
      "metadata": {
        "id": "FsdG_PaKa7kq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer import iterators\n",
        "\n",
        "batchsize = 128\n",
        "\n",
        "train_iter = iterators.SerialIterator(train, batchsize)\n",
        "test_iter = iterators.SerialIterator(test, batchsize,\n",
        "                                     repeat=False, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bDSS7S1a7ks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Iteratorについて\n",
        "\n",
        "- Chainerがいくつか用意しているIteratorの一種である`SerialIterator`は、データセットの中のデータを順番に取り出してくる最もシンプルなIteratorです。\n",
        "- 引数にデータセットオブジェクトと、バッチサイズを取ります。\n",
        "- また、このとき渡したデータセットから、何周も何周もデータを繰り返し読み出す必要がある場合は`repeat`引数を`True`とし、1周が終わったらそれ以上データを取り出したくない場合はこれを`False`とします。デフォルトでは、`True`になっています。\n",
        "- `shuffle`引数に`True`を渡すと、データセットから取り出されてくるデータの順番をエポックごとにランダムに変更します。\n",
        "\n",
        "ここで、`batchsize = 128`としているので、ここで作成した訓練データ用の`Iterator`である`train_iter`およびテストデータ用の`Iterator`である`test_iter`は、それぞれ128枚の数字画像データを一括りにして返す`Iterator`ということになります。"
      ]
    },
    {
      "metadata": {
        "id": "F4ycO_cca7ks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. モデルの定義\n",
        "\n",
        "ここでは、シンプルな三層パーセプトロンを定義します。これは全結合層のみからなるネットワークです。中間層のユニット数は適当に100とし、出力は10クラスなので10とします。ここで用いるMNISTデータセットは10種のラベルを持つためです。では、モデルを定義するために必要な`Link`, `Function`, そして`Chain`について、簡単にここで説明を行います。\n",
        "\n",
        "### LinkとFunction\n",
        "\n",
        "- Chainerでは、ニューラルネットワークの各層を、`Link`と`Function`に区別します。\n",
        "- **`Link`は、パラメータを持つ関数です。**\n",
        "- **`Function`は、パラメータを持たない関数です。**\n",
        "- これらを組み合わせてモデルを記述します。\n",
        "- パラメータを持つ層は、`chainer.links`モジュール以下にたくさん用意されています。\n",
        "- パラメータを持たない層は、`chainer.functions`モジュール以下にたくさん用意されています。\n",
        "- これらを簡単に使うために、\n",
        "    ```\n",
        "    import chainer.links as L\n",
        "    import chainer.functions as F\n",
        "    ```\n",
        "    と別名を与えて、`L.Convolution2D(...)`や`F.relu(...)`のように用いる慣習があります。\n",
        "\n",
        "### Chain\n",
        "\n",
        "- Chainは、パラメータを持つ層＝**`Link`をまとめておくためのクラス**です。\n",
        "- パラメータを持つということは、基本的にモデルの学習の際にそれらを更新していく必要があるということです（例外はあります）。\n",
        "- そこで、学習中に`Optimizer`が更新すべき全てのパラメータを簡単に取得できるように、`Chain`で一箇所にまとめておきます。\n",
        "\n",
        "### Chainを継承して定義されるモデル\n",
        "\n",
        "- モデルは`Chain`クラスを継承したクラスとして定義されることが多いです。\n",
        "- その場合、モデルを表すクラスのコンストラクタで、親クラスのコンストラクタにキーワード引数の形で登録したい層の名前と、オブジェクトを渡しておくと、自動的に`Optimizer`から見つけられる形で保持しておいてくれます。\n",
        "- これは、別の場所で`add_link`メソッドを使っても行うことができます。 \n",
        "- また、関数呼び出しのようにしてモデルに`()`アクセサでデータを渡せるように、`__call__`メソッドを定義して、その中にforward処理を記述すると便利です。\n",
        "\n",
        "### GPUで実行するには\n",
        "\n",
        "- `Chain`クラスは`to_gpu`メソッドを持ち、この引数にGPU IDを指定すると、指定したGPU IDのメモリ上にモデルの全パラメータを転送します。\n",
        "- これはモデル内部でのforward/backward計算をその指定したGPU上で行うために必要になります。\n",
        "- これを行わない場合、それらの処理はCPU上で行われます。\n",
        "\n",
        "---\n",
        "\n",
        "それでは実際にモデルの定義を行い、オブジェクトを作って、GPUに送信してみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "a7COhg2Ia7kt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.links as L\n",
        "import chainer.functions as F\n",
        "\n",
        "class MLP(chainer.Chain):\n",
        "\n",
        "    def __init__(self, n_mid_units=100, n_out=10):\n",
        "        # パラメータを持つ層の登録\n",
        "        super(MLP, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l1=L.Linear(None, n_mid_units)\n",
        "            self.l2=L.Linear(None, n_mid_units)\n",
        "            self.l3=L.Linear(None, n_out)\n",
        "\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # データを受け取った際のforward計算を書く\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = F.relu(self.l2(h1))\n",
        "        return self.l3(h2)\n",
        "\n",
        "gpu_id = 0  # change to -1 if not using GPU\n",
        "\n",
        "model = MLP()\n",
        "if gpu_id >= 0:\n",
        "    model.to_gpu(gpu_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLe3zkWQa7kv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NOTE\n",
        "\n",
        "ここで、`L.Linear`クラスは全結合層を意味します。コンストラクタの第一引数に`None`を渡すと、実行時に、データがその層に入力された瞬間、必要な数の入力側ユニット数を自動的に計算し、`(n_input)` $\\times$ `n_mid_units`の大きさの行列を作成し、パラメータとして保持します。これは後々、畳み込み層を全結合層の前に配置する際などに便利な機能です。\n",
        "\n",
        "前述のように、`Link`はパラメータを持つので、そのパラメータの値にアクセスすることができます。例えば、上のモデル`MLP`は`l1`という名前の全結合相が登録されています。この全結合相は`W`と`b`という2つのパラメータを持ちます。これらは外からアクセスすることができます。例えば`b`へアクセスするには、以下のようにします。"
      ]
    },
    {
      "metadata": {
        "id": "A8yORmH1a7kw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bc072adc-53a6-456d-8c6f-b9c717f8c52d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518682251950,
          "user_tz": -540,
          "elapsed": 730,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('1つ目の全結合相のバイアスパラメータの形は、', model.l1.b.shape)\n",
        "print('初期化直後のその値は、', model.l1.b.data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1つ目の全結合相のバイアスパラメータの形は、 (100,)\n",
            "初期化直後のその値は、 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VWVaCPLJa7ky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. 最適化手法の選択\n",
        "\n",
        "Chainerは多くの最適化手法を提供しています。`chainer.optimizers`モジュール以下にそれらはあります。ここでは最もシンプルな勾配降下法の手法である`optimizers.SGD`を用います。Optimizerのオブジェクトには、`setup`メソッドを使ってモデル（`Chain`オブジェクト）を渡します。こうすることでOptimizerは、自身が更新すべきモデル内のパラメータを自動的にたどってくれます。\n",
        "\n",
        "他にもいろいろな最適化手法が手軽に試せるので、色々と試してみて結果の変化を見てみてください。例えば、下の`chainer.optimizers.SGD`のうち`SGD`の部分を`MomentumSGD`, `RMSprop`,  `Adam`などに変えて、結果の違いを見てみましょう。"
      ]
    },
    {
      "metadata": {
        "id": "N0hTSAL4a7ky",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.01)\n",
        "optimizer.setup(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vx6vKLBa7k0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NOTE\n",
        "\n",
        "今回はSGDのコンストラクタの`lr`という引数に $0.01$ を与えました。この値は学習率として知られ、モデルをうまく訓練して良いパフォーマンスを発揮させるために調整する必要がある重要な**ハイパーパラメータ**として知られています。"
      ]
    },
    {
      "metadata": {
        "id": "DjSmOmvRa7k1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. 学習ループ\n",
        "\n",
        "いよいよ学習ループです。今回は分類問題なので、`softmax_cross_entropy`というロス関数を使って最小化すべきロスの値を計算します。\n",
        "\n",
        "Chainerでは、`Function`や`Link`を使ってモデルのforward計算を行い、結果と正解ラベルを`Function`の一種でありスカラ値を返すロス関数に渡してやり、ロスの計算を行うと、それは他の`Link`や`Function`と同じく、`Variable`オブジェクトを返します。`Variable`オブジェクトはこれまでの計算過程をあとから逆向きに辿り返すための参照を保持しているため、`Variable.backward`メソッドを呼ぶだけで、自動的にそこからこれまでの計算過程を遡って、途中で施された計算に用いられたパラメータの勾配を計算してくれます。\n",
        "\n",
        "つまり、学習ループの1回の中で行うのは、以下の4項目です。\n",
        "\n",
        "1. モデルにデータを渡して出力`y`を得る\n",
        "2. `y`と正解ラベル`t`を使って、最小化すべきロスの値を`softmax_cross_entropy`関数で計算する\n",
        "3. `softmax_cross_entropy`関数の出力`Variable`の`backward`メソッドを呼んで、モデル内部のパラメータに`grad`プロパティ（これがパラメータ更新に使われる勾配）を持たせる\n",
        "4. Optimizerの`update`メソッドを呼び、3.で計算した`grad`を使って全パラメータを更新する\n",
        "\n",
        "以上です。では実際に訓練ループを書いていきます。"
      ]
    },
    {
      "metadata": {
        "id": "BHcWKhRPa7k2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 17
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "2b9ce02e-4fe2-4c1d-d18e-a7aeecd6503f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518682307149,
          "user_tz": -540,
          "elapsed": 54334,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from chainer.dataset import concat_examples\n",
        "from chainer.cuda import to_cpu\n",
        "\n",
        "max_epoch = 10\n",
        "\n",
        "while train_iter.epoch < max_epoch:\n",
        "    \n",
        "    # ---------- 学習の1イテレーション ----------\n",
        "    train_batch = train_iter.next()\n",
        "    x, t = concat_examples(train_batch, gpu_id)\n",
        "    \n",
        "    # 予測値の計算\n",
        "    y = model(x)\n",
        "\n",
        "    # ロスの計算\n",
        "    loss = F.softmax_cross_entropy(y, t)\n",
        "\n",
        "    # 勾配の計算\n",
        "    model.cleargrads()\n",
        "    loss.backward()\n",
        "\n",
        "    # パラメータの更新\n",
        "    optimizer.update()\n",
        "    # --------------- ここまで ----------------\n",
        "\n",
        "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
        "    # モデルの汎化性能が向上していることをチェックしよう\n",
        "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
        "\n",
        "        # ロスの表示\n",
        "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
        "            train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
        "\n",
        "        test_losses = []\n",
        "        test_accuracies = []\n",
        "        while True:\n",
        "            test_batch = test_iter.next()\n",
        "            x_test, t_test = concat_examples(test_batch, gpu_id)\n",
        "\n",
        "            # テストデータをforward\n",
        "            y_test = model(x_test)\n",
        "\n",
        "            # ロスを計算\n",
        "            loss_test = F.softmax_cross_entropy(y_test, t_test)\n",
        "            test_losses.append(to_cpu(loss_test.data))\n",
        "\n",
        "            # 精度を計算\n",
        "            accuracy = F.accuracy(y_test, t_test)\n",
        "            accuracy.to_cpu()\n",
        "            test_accuracies.append(accuracy.data)\n",
        "            \n",
        "            if test_iter.is_new_epoch:\n",
        "                test_iter.epoch = 0\n",
        "                test_iter.current_position = 0\n",
        "                test_iter.is_new_epoch = False\n",
        "                test_iter._pushed_position = None\n",
        "                break\n",
        "\n",
        "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
        "            np.mean(test_losses), np.mean(test_accuracies)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:01 train_loss:0.7972 val_loss:0.7641 val_accuracy:0.8286\n",
            "epoch:02 train_loss:0.4790 val_loss:0.4431 val_accuracy:0.8841\n",
            "epoch:03 train_loss:0.3785 val_loss:0.3625 val_accuracy:0.8993\n",
            "epoch:04 train_loss:0.2973 val_loss:0.3270 val_accuracy:0.9079\n",
            "epoch:05 train_loss:0.2120 val_loss:0.3032 val_accuracy:0.9143\n",
            "epoch:06 train_loss:0.2209 val_loss:0.2875 val_accuracy:0.9176\n",
            "epoch:07 train_loss:0.3127 val_loss:0.2739 val_accuracy:0.9202\n",
            "epoch:08 train_loss:0.2458 val_loss:0.2620 val_accuracy:0.9252\n",
            "epoch:09 train_loss:0.2618 val_loss:0.2513 val_accuracy:0.9283\n",
            "epoch:10 train_loss:0.2291 val_loss:0.2431 val_accuracy:0.9295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UCodn6XSa7k4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. 学習済みモデルを保存する\n",
        "\n",
        "Chainerには2つのシリアライズ機能が用意されています。一つはHDF5形式でモデルを保存するもので、もう一つはNumPyのNPZ形式でモデルを保存するものです。今回は、追加ライブラリのインストールが必要なHDF5ではなく、NumPy標準機能で提供されているシリアライズ機能を利用したNPZ形式でのモデルの保存を行います。"
      ]
    },
    {
      "metadata": {
        "id": "KLTb41DYa7k5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "300f21c8-f019-4edd-e701-c3461d5c8750",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518682307995,
          "user_tz": -540,
          "elapsed": 831,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer import serializers\n",
        "\n",
        "serializers.save_npz('my_mnist.model', model)\n",
        "\n",
        "# ちゃんと保存されていることを確認\n",
        "%ls -la my_mnist.model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 333851 Feb 15 08:11 my_mnist.model\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdskF19ua7k7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. 保存したモデルを読み込んで推論する\n",
        "\n",
        "今しがた保存したNPZファイルを読み込んで、テストデータに対して予測を計算させてみます。NPZファイルにはパラメータが保存されているので、forward計算のロジックを持つモデルのオブジェクトをまず作成し、そのパラメータを先程保存したNPZが持つ値で上書きすることで学習直後のモデルの状態を復元します。"
      ]
    },
    {
      "metadata": {
        "id": "D0p6AcOMa7k8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# まず同じモデルのオブジェクトを作る\n",
        "infer_model = MLP()\n",
        "\n",
        "# そのオブジェクトに保存済みパラメータをロードする\n",
        "serializers.load_npz('my_mnist.model', infer_model)\n",
        "\n",
        "# GPU上で計算させるために、モデルをGPUに送る\n",
        "if gpu_id >= 0:\n",
        "    infer_model.to_gpu(gpu_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8AtSuBSa7k-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b76e4029-0e89-4f05-a788-9f7246008dd4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518682309207,
          "user_tz": -540,
          "elapsed": 598,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# テストデータ\n",
        "x, t = test[0]\n",
        "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "print('label:', t)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nupSB/wclp6FycBcGXAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9d2da99588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1VBhEIALa7lE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8931b210-7559-46ad-edcc-c4e91a5cdd52",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1518682309876,
          "user_tz": -540,
          "elapsed": 641,
          "user": {
            "displayName": "keisuke umezawa",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103766488840000528829"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from chainer.cuda import to_gpu\n",
        "\n",
        "# ミニバッチの形にする（ここではサイズ1のミニバッチにするが、\n",
        "# 複数まとめてサイズnのミニバッチにしてまとめて推論することもできる）\n",
        "print(x.shape, end=' -> ')\n",
        "x = x[None, ...]\n",
        "print(x.shape)\n",
        "\n",
        "# GPU上で計算させるため、データもGPU上に送る\n",
        "if gpu_id >= 0:\n",
        "    x = to_gpu(x, 0)\n",
        "\n",
        "# モデルのforward関数に渡す\n",
        "y = infer_model(x)\n",
        "\n",
        "# Variable形式で出てくるので中身を取り出す\n",
        "y = y.data\n",
        "\n",
        "# 結果をCPUに送る\n",
        "y = to_cpu(y)\n",
        "\n",
        "# 最大値のインデックスを見る\n",
        "pred_label = y.argmax(axis=1)\n",
        "\n",
        "print('predicted label:', pred_label[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784,) -> (1, 784)\n",
            "predicted label: 7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
